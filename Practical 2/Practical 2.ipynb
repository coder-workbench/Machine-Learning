{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727df070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4ea900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0                            key  fare_amount  \\\n",
      "0         24238194    2015-05-07 19:52:06.0000003          7.5   \n",
      "1         27835199    2009-07-17 20:04:56.0000002          7.7   \n",
      "2         44984355   2009-08-24 21:45:00.00000061         12.9   \n",
      "3         25894730    2009-06-26 08:22:21.0000001          5.3   \n",
      "4         17610152  2014-08-28 17:47:00.000000188         16.0   \n",
      "...            ...                            ...          ...   \n",
      "199995    42598914   2012-10-28 10:49:00.00000053          3.0   \n",
      "199996    16382965    2014-03-14 01:09:00.0000008          7.5   \n",
      "199997    27804658   2009-06-29 00:42:00.00000078         30.9   \n",
      "199998    20259894    2015-05-20 14:56:25.0000004         14.5   \n",
      "199999    11951496   2010-05-15 04:08:00.00000076         14.1   \n",
      "\n",
      "                pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
      "0       2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
      "1       2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
      "2       2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
      "3       2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
      "4       2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
      "...                         ...               ...              ...   \n",
      "199995  2012-10-28 10:49:00 UTC        -73.987042        40.739367   \n",
      "199996  2014-03-14 01:09:00 UTC        -73.984722        40.736837   \n",
      "199997  2009-06-29 00:42:00 UTC        -73.986017        40.756487   \n",
      "199998  2015-05-20 14:56:25 UTC        -73.997124        40.725452   \n",
      "199999  2010-05-15 04:08:00 UTC        -73.984395        40.720077   \n",
      "\n",
      "        dropoff_longitude  dropoff_latitude  passenger_count  \n",
      "0              -73.999512         40.723217                1  \n",
      "1              -73.994710         40.750325                1  \n",
      "2              -73.962565         40.772647                1  \n",
      "3              -73.965316         40.803349                3  \n",
      "4              -73.973082         40.761247                5  \n",
      "...                   ...               ...              ...  \n",
      "199995         -73.986525         40.740297                1  \n",
      "199996         -74.006672         40.739620                1  \n",
      "199997         -73.858957         40.692588                2  \n",
      "199998         -73.983215         40.695415                1  \n",
      "199999         -73.985508         40.768793                1  \n",
      "\n",
      "[200000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(r'C:\\Users\\ayush\\Microsoft\\Downloads\\uber.csv')\n",
    "\n",
    "# view dataset\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6537fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "# print(df['pickup_datetime'])\n",
    "df['hour'] = df['pickup_datetime'].dt.hour\n",
    "# print(df['hour'])\n",
    "df['day_of_week'] = df['pickup_datetime'].dt.dayofweek\n",
    "# print(df['day_of_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a722874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0                            key  fare_amount  \\\n",
      "0         24238194    2015-05-07 19:52:06.0000003          7.5   \n",
      "1         27835199    2009-07-17 20:04:56.0000002          7.7   \n",
      "2         44984355   2009-08-24 21:45:00.00000061         12.9   \n",
      "3         25894730    2009-06-26 08:22:21.0000001          5.3   \n",
      "4         17610152  2014-08-28 17:47:00.000000188         16.0   \n",
      "...            ...                            ...          ...   \n",
      "199995    42598914   2012-10-28 10:49:00.00000053          3.0   \n",
      "199996    16382965    2014-03-14 01:09:00.0000008          7.5   \n",
      "199997    27804658   2009-06-29 00:42:00.00000078         30.9   \n",
      "199998    20259894    2015-05-20 14:56:25.0000004         14.5   \n",
      "199999    11951496   2010-05-15 04:08:00.00000076         14.1   \n",
      "\n",
      "                 pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
      "0      2015-05-07 19:52:06+00:00        -73.999817        40.738354   \n",
      "1      2009-07-17 20:04:56+00:00        -73.994355        40.728225   \n",
      "2      2009-08-24 21:45:00+00:00        -74.005043        40.740770   \n",
      "3      2009-06-26 08:22:21+00:00        -73.976124        40.790844   \n",
      "4      2014-08-28 17:47:00+00:00        -73.925023        40.744085   \n",
      "...                          ...               ...              ...   \n",
      "199995 2012-10-28 10:49:00+00:00        -73.987042        40.739367   \n",
      "199996 2014-03-14 01:09:00+00:00        -73.984722        40.736837   \n",
      "199997 2009-06-29 00:42:00+00:00        -73.986017        40.756487   \n",
      "199998 2015-05-20 14:56:25+00:00        -73.997124        40.725452   \n",
      "199999 2010-05-15 04:08:00+00:00        -73.984395        40.720077   \n",
      "\n",
      "        dropoff_longitude  dropoff_latitude  passenger_count  hour  \\\n",
      "0              -73.999512         40.723217                1    19   \n",
      "1              -73.994710         40.750325                1    20   \n",
      "2              -73.962565         40.772647                1    21   \n",
      "3              -73.965316         40.803349                3     8   \n",
      "4              -73.973082         40.761247                5    17   \n",
      "...                   ...               ...              ...   ...   \n",
      "199995         -73.986525         40.740297                1    10   \n",
      "199996         -74.006672         40.739620                1     1   \n",
      "199997         -73.858957         40.692588                2     0   \n",
      "199998         -73.983215         40.695415                1    14   \n",
      "199999         -73.985508         40.768793                1     4   \n",
      "\n",
      "        day_of_week  \n",
      "0                 3  \n",
      "1                 4  \n",
      "2                 0  \n",
      "3                 4  \n",
      "4                 3  \n",
      "...             ...  \n",
      "199995            6  \n",
      "199996            4  \n",
      "199997            0  \n",
      "199998            2  \n",
      "199999            5  \n",
      "\n",
      "[200000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# check datasets for more columns we added 'hour' and 'day_of_week' column\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77484ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['Unnamed: 0', 'key', 'pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d7daab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
      "0               7.5        -73.999817        40.738354         -73.999512   \n",
      "1               7.7        -73.994355        40.728225         -73.994710   \n",
      "2              12.9        -74.005043        40.740770         -73.962565   \n",
      "3               5.3        -73.976124        40.790844         -73.965316   \n",
      "4              16.0        -73.925023        40.744085         -73.973082   \n",
      "...             ...               ...              ...                ...   \n",
      "199995          3.0        -73.987042        40.739367         -73.986525   \n",
      "199996          7.5        -73.984722        40.736837         -74.006672   \n",
      "199997         30.9        -73.986017        40.756487         -73.858957   \n",
      "199998         14.5        -73.997124        40.725452         -73.983215   \n",
      "199999         14.1        -73.984395        40.720077         -73.985508   \n",
      "\n",
      "        dropoff_latitude  passenger_count  hour  day_of_week  \n",
      "0              40.723217                1    19            3  \n",
      "1              40.750325                1    20            4  \n",
      "2              40.772647                1    21            0  \n",
      "3              40.803349                3     8            4  \n",
      "4              40.761247                5    17            3  \n",
      "...                  ...              ...   ...          ...  \n",
      "199995         40.740297                1    10            6  \n",
      "199996         40.739620                1     1            4  \n",
      "199997         40.692588                2     0            0  \n",
      "199998         40.695415                1    14            2  \n",
      "199999         40.768793                1     4            5  \n",
      "\n",
      "[200000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# check datasets for removal of columns we removed 'first_column with no name', 'key' and 'pickup_datetime' column\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953b4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b3cc569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = df_imputed.drop(columns=['fare_amount'])  # create new dataset ignoring 'fare_amount' column\n",
    "y = df_imputed['fare_amount']  # create a series of only 'fare_amount' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbcf2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95669338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features (scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3404f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea140022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)  # You can experiment with different alpha values\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "574e03f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Lasso Regression\n",
    "lasso_model = Lasso(alpha=0.1)  # You can experiment with different alpha values\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = lasso_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16245eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"{model_name} - R2 Score: {r2:.4f}, RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42a3de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - R2 Score: 0.0007, RMSE: 10.31\n",
      "Ridge Regression - R2 Score: 0.0007, RMSE: 10.31\n",
      "Lasso Regression - R2 Score: 0.0003, RMSE: 10.31\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, y_pred_lr, \"Linear Regression\")\n",
    "evaluate_model(y_test, y_pred_ridge, \"Ridge Regression\")\n",
    "evaluate_model(y_test, y_pred_lasso, \"Lasso Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0408925f-dfe8-4486-bf4e-f5430559a739",
   "metadata": {},
   "source": [
    "# Practical 2 B)\n",
    "Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37ab4c27-1069-419b-bfa7-23baf5471f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01fe723f-9051-486b-aa37-307d57595c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univariate Analysis:\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "diabetes_data = pd.read_csv(r\"C:\\Users\\ayush\\Microsoft\\Downloads\\diabetes.csv\")\n",
    "\n",
    "# Univariate analysis\n",
    "print(\"Univariate Analysis:\")\n",
    "print(diabetes_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d1d6acd-61a7-4923-a882-80ca81753379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness: Pregnancies                 0.901674\n",
      "Glucose                     0.173754\n",
      "BloodPressure              -1.843608\n",
      "SkinThickness               0.109372\n",
      "Insulin                     2.272251\n",
      "BMI                        -0.428982\n",
      "DiabetesPedigreeFunction    1.919911\n",
      "Age                         1.129597\n",
      "Outcome                     0.635017\n",
      "dtype: float64\n",
      "Kurtosis: Pregnancies                 0.159220\n",
      "Glucose                     0.640780\n",
      "BloodPressure               5.180157\n",
      "SkinThickness              -0.520072\n",
      "Insulin                     7.214260\n",
      "BMI                         3.290443\n",
      "DiabetesPedigreeFunction    5.594954\n",
      "Age                         0.643159\n",
      "Outcome                    -1.600930\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate skewness and kurtosis\n",
    "print(\"Skewness:\", diabetes_data.skew())\n",
    "print(\"Kurtosis:\", diabetes_data.kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53b21bb0-9791-4b68-8064-8f5ae404120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Metrics:\n",
      "Mean Squared Error: 0.17104527280850096\n"
     ]
    }
   ],
   "source": [
    "# Bivariate analysis: Linear regression\n",
    "X = diabetes_data[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "y = diabetes_data['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Linear Regression Metrics:\")\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e07c24ce-e0ea-4d29-b14b-e6fc0f6e1f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.7467532467532467\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80        99\n",
      "           1       0.64      0.67      0.65        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.73      0.73       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "Confusion Matrix:\n",
      " [[78 21]\n",
      " [18 37]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Bivariate analysis: Logistic regression\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_logistic))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fac992ae-34b9-4528-88c0-f47ea9039dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Regression Metrics:\n",
      "Cross Validation Scores: [0.25670474 0.16630122 0.34107831 0.35547976 0.26482727]\n"
     ]
    }
   ],
   "source": [
    "# Multiple Regression analysis\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "scores = cross_val_score(rf_model, X, y, cv=5)\n",
    "\n",
    "print(\"Multiple Regression Metrics:\")\n",
    "print(\"Cross Validation Scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1822f7e8-1ece-47d4-94ea-e021d193ffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Linear Regression and Logistic Regression:\n",
      "Linear Regression Mean Squared Error: 0.17104527280850096\n",
      "Logistic Regression Accuracy: 0.7467532467532467\n"
     ]
    }
   ],
   "source": [
    "# Compare the results of linear regression and logistic regression\n",
    "print(\"Comparison of Linear Regression and Logistic Regression:\")\n",
    "print(\"Linear Regression Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cdcc70d-bca9-4d3f-b794-deaf578d3464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Logistic Regression and Multiple Regression:\n",
      "Logistic Regression Accuracy: 0.7467532467532467\n",
      "Multiple Regression Cross Validation Scores: [0.25670474 0.16630122 0.34107831 0.35547976 0.26482727]\n"
     ]
    }
   ],
   "source": [
    "# Compare the results of logistic regression and multiple regression\n",
    "print(\"Comparison of Logistic Regression and Multiple Regression:\")\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(\"Multiple Regression Cross Validation Scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814bbc57-b47e-4690-84bb-c2786f67f66f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
